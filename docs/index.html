<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="FaceAttributeAttack">
  <meta name="keywords" content="Facial Privacy, Forenisc Classifiers Text-guidance, Image-Reference, StyleGAN">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- <title>CLIP2Protect</title> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
  <style>
  @import url('https://fonts.cdnfonts.com/css/menlo');
  </style>
<body>
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
         <h1 class="title is-2 publication-title">
           <!-- <i class="fas fa-shield-alt"></i> -->
           </span>Evading Forensic Classifiers with Attribute-Conditioned Adversarial Faces</h1>
        <div class="is-size-5 publication-authors">
           <span class="author-block">
             <a href="https://fahadshamshad.github.io/">Fahad Shamshad</a></sup>,
           </span>
           <span class="author-block">
             <a href="https://scholar.google.com/citations?user=LfIXeHQAAAAJ&hl=en">Koushik Srivatsan</a></sup>,
           </span>
           <span class="author-block">
             <a href="https://scholar.google.com/citations?user=2qx0RnEAAAAJ&hl=en">Karthik Nandakumar</a></sup>
           </span>
        </div>

        <div class="is-size-5 publication-authors">
          <span class="author-block"></sup><strong>MBZUAI, UAE.</strong></span>
        </div>
          
        <div class="is-size-5 publication-authors">
          <span class="author-block"><strong style="font-size: 1.5em;">[</strong><strong style="font-family: 'Google Sans', sans-serif; font-weight: bold; font-size: 1.4em; color: slateblue;">Accepted in CVPR 2023</strong><strong style="font-size: 1.5em;">]</strong></span>
        </div>

        <div class="column has-text-centered">
          <div class="publication-links">
            <!-- PDF Link. -->
            <span class="link-block">
              <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Shamshad_Evading_Forensic_Classifiers_With_Attribute-Conditioned_Adversarial_Faces_CVPR_2023_paper.pdf"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                </span>
                <span>Paper</span>
              </a>
            </span>

            <!-- Code Link. -->
            <span class="link-block">
              <a href="https://github.com/koushiksrivats/face_attribute_attack"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fab fa-github"></i>
                </span>
                <span>Code</span>
                </a>
            </span>

            
            <!-- Video Link. -->
            <span class="link-block">
              <a href="https://www.youtube.com/watch?v=ZkPuU3lIK9U"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fab fa-youtube"></i>
                </span>
                <span>Video</span>
              </a>
            </span>

            
            <!-- PDF Link. -->
            <span class="link-block">
              <a href="https://openaccess.thecvf.com/content/CVPR2023/supplemental/Shamshad_Evading_Forensic_Classifiers_CVPR_2023_supplemental.pdf"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                </span>
                <span>Supplementary</span>
              </a>
            </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<!-- Add an image -->
<section class="hero-body">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
          <img src="./static/images/pipeline.png">
      </div>
    </div>
  </div>
</section>


<!-- Abstract. -->
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="subtitle has-text-justified">
          <p>
            The ability of generative models to produce highly realistic synthetic face images has raised security and ethical concerns. 
            As a first line of defense against such fake faces, deep learning based forensic classifiers have been developed. 
            While these forensic models can detect whether a face image is synthetic or real with high accuracy, they are also vulnerable to adversarial attacks. 
            Although such attacks can be highly successful in evading detection by forensic classifiers, they introduce visible noise patterns that are detectable through careful human scrutiny. 
            Additionally, these attacks assume access to the target model(s) which may not always be true.
            Attempts have been made to directly perturb the latent space of GANs to produce adversarial fake faces that can circumvent forensic classifiers. 
            In this work, we go one step further and show that it is possible to successfully generate adversarial fake faces with a specified set of attributes (e.g., hair color, eye size, race, gender, etc.). 
            To achieve this goal, we leverage the state-of-the-art generative model StyleGAN with disentangled representations, which enables a range of modifications without leaving the manifold of natural images. 
            We propose a framework to search for adversarial latent codes within the feature space of StyleGAN, where the search can be guided either by a text prompt or a reference image. 
            We also propose a meta-learning based optimization strategy to achieve transferable performance on unknown target models.
            Extensive experiments demonstrate that the proposed approach can produce semantically manipulated adversarial fake faces, which are true to the specified attribute set and can successfully fool forensic face classifiers, while remaining undetectable by humans.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>

</code></pre>
  </div>
</section> -->
  


<footer class="footer">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website adapted from the following <a href="https://github.com/nerfies/nerfies.github.io">source code</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
